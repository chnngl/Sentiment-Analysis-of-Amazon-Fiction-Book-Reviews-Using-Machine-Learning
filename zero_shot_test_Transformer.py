# -*- coding: utf-8 -*-
"""zero_shot_test.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14_eJH7ohPbZjMWy_qp3Wc2ygM68JWGvu
"""

from google.colab import files
import pandas as pd
uploaded = files.upload()

df = pd.read_csv("balanced30k.csv")
df.head()

# Preprocessing with basic text cleanup
import re
def clean_for_bert(text):
    text = str(text)
    text = re.sub(r'\s+', ' ', text)             # normalize spaces
    return text.strip()

df['cleaned_text'] = df['review/text'].apply(clean_for_bert)
df.head()

df.to_csv('balanced30k_processed_zero_shot.csv', index=False)

# Split the dataset
from sklearn.model_selection import train_test_split

X = df['review/text']
y = df['label']

X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)
X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=1/3, random_state=42, stratify=y_temp)

!pip install transformers

from transformers import AutoTokenizer, AutoModelForSequenceClassification, TextClassificationPipeline
import torch

model_name = "cardiffnlp/twitter-roberta-base-sentiment"

# Load tokenizer and model separately
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# Create pipeline with truncation enabled
classifier = TextClassificationPipeline(
    model=model,
    tokenizer=tokenizer,
    return_all_scores=True,
    truncation=True,
    max_length=512,
    device=0 if torch.cuda.is_available() else -1
)

# Manual batching
from tqdm import tqdm  # Optional progress bar

results = []
batch_size = 16
texts_to_predict = X_test.tolist()

for i in tqdm(range(0, len(texts_to_predict), batch_size)):
    batch = texts_to_predict[i:i + batch_size]
    preds = classifier(batch)
    results.extend(preds)

# Convert predictions to class labels 0, 1, 2
y_pred = [
    int(max(p, key=lambda x: x['score'])['label'].split('_')[-1])
    for p in results
]

# Evaluate performance
from sklearn.metrics import classification_report
print("\n Zero-Shot Twitter Transformer Performance on Test Set:")
print(classification_report(y_test.tolist(), y_pred, zero_division=0))

# Using pre-trained multilingual review-based sentiment model
model_name = "nlptown/bert-base-multilingual-uncased-sentiment"

# Load tokenizer and model separately
tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForSequenceClassification.from_pretrained(model_name)

# Create pipeline with truncation enabled
classifier = TextClassificationPipeline(
    model=model,
    tokenizer=tokenizer,
    return_all_scores=True,
    truncation=True,
    max_length=512,
    device=0 if torch.cuda.is_available() else -1
)

# Manual batching (safe and scalable)
from tqdm import tqdm  # Optional progress bar

results = []
batch_size = 16
texts_to_predict = X_test.tolist()

for i in tqdm(range(0, len(texts_to_predict), batch_size)):
    batch = texts_to_predict[i:i + batch_size]
    preds = classifier(batch)
    results.extend(preds)

# Map 1 and 2 stars to 0, 3 stars to 1, 5 stars to 2
def map_star_label(star_label):
    if "1 star" in star_label or "2 stars" in star_label:
        return 0  # Negative
    elif "3 stars" in star_label:
        return 1  # Neutral
    else:
        return 2  # Positive

y_pred = [
    map_star_label(max(r, key=lambda x: x['score'])['label'])
    for r in results
]

# Evaluate performance
print("\n Zero-shot Review-Based Transformer Performance on Test Set:")
print(classification_report(y_test.tolist(), y_pred, zero_division=0))