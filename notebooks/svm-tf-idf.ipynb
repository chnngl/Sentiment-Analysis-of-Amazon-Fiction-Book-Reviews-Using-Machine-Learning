{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4200454,"sourceType":"datasetVersion","datasetId":2476732}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport nltk\nnltk.data.path.append(\"/usr/share/nltk_data\")\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import pandas as pd\nbr = pd.read_csv('/kaggle/input/amazon-books-reviews/Books_rating.csv')\nbr.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"bd = pd.read_csv('/kaggle/input/amazon-books-reviews/books_data.csv')\nbd.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"books = pd.merge(br,bd, on = 'Title')\nbooks.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = books[['Title','review/score','review/text','categories']]\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.drop_duplicates(inplace = True)\ndf.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.dropna(inplace=True)\ndf.isna().sum()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df[df['categories'].str.contains('Fiction', case=False, na=False)]\ndf.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df = df[~df['categories'].str.contains('Nonfiction', case=False, na=False)]\ndf.shape","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['categories'] = df['categories'].str.extract(r'\\'(.*)\\'')\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"df['word_count'] = df['review/text'].apply(lambda x: len(x.split(' ')))\ndf.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Negative class: 1 star\nneg_df = df[df['review/score'].isin([1, 2])]\n\n# Neutral class: 3 stars\nneu_df = df[df['review/score'] == 3]\n\n# Positive class: 4 or 5 stars\npos_df = df[df['review/score'].isin([4, 5])]\n\nprint(len(neg_df), len(neu_df), len(pos_df))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"neg_10k = neg_df.sample(n=10000, random_state=42)\nneu_10k = neu_df.sample(n=10000, random_state=42)\npos_10k = pos_df.sample(n=10000, random_state=42)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"balanced_df = pd.concat([neg_10k, neu_10k, pos_10k])\nbalanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)  # Shuffle","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def map_label(score):\n    if score in [1, 2]:\n        return 0  # Negative\n    elif score == 3:\n        return 1  # Neutral\n    else:\n        return 2  # Positive\n\nbalanced_df['label'] = balanced_df['review/score'].apply(map_label)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"balanced_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"balanced_df.to_csv('balanced30k.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import nltk\n\nnltk.download('averaged_perceptron_tagger_eng')\nnltk.download('punkt')\nnltk.download('wordnet')\n\nprint(\"All NLTK data downloaded!\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import re\nfrom nltk.stem import WordNetLemmatizer\nlemmatizer = WordNetLemmatizer()\n\ndef clean_text_ml(text):\n    text = str(text).lower()\n    text = re.sub(r'<.*?>', '', text)                      # Remove HTML tags\n    text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)    # Remove URLs\n    text = re.sub(r'@\\w+|\\#', '', text)                    # Remove mentions and hashtags\n    text = re.sub(r'[^\\w\\s]', '', text)                    # Remove punctuation except underscore\n    text = re.sub(r'\\d+', '', text)                        # Remove digits/numbers\n    text = re.sub(r'\\s+', ' ', text).strip()               # Normalize whitespace\n     # Lemmatize\n    words = text.split()\n    text = ' '.join([lemmatizer.lemmatize(word) for word in words])\n    return text","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"balanced_df['cleaned_text_ml'] = balanced_df['review/text'].apply(clean_text_ml)\nbalanced_df.head()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"balanced_df.to_csv('balanced30k_SVM_cleaned.csv', index=False)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\nX = balanced_df['cleaned_text_ml']\ny = balanced_df['label']\n\nX_train, X_temp, y_train, y_temp = train_test_split(\n    X, y, test_size=0.3, random_state=42, stratify=y)\n\nX_val, X_test, y_val, y_test = train_test_split(\n    X_temp, y_temp, test_size=1/3, random_state=42, stratify=y_temp)\n\n\nprint(f\"Train size: {len(X_train)} ({len(X_train)/len(X):.1%})\")\nprint(f\"Val size:   {len(X_val)} ({len(X_val)/len(X):.1%})\")\nprint(f\"Test size:  {len(X_test)} ({len(X_test)/len(X):.1%})\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.svm import LinearSVC\nfrom sklearn.metrics import classification_report\n\n# Define grid manually\nparam_grid = [\n    #{'C': 0.01, 'stop_words': 'english', 'ngram_range': (1, 2), 'max_features': 20000},\n    #{'C': 0.005, 'stop_words': 'english', 'ngram_range': (1, 2), 'max_features': 20000},\n    #{'C': 0.005, 'stop_words': None, 'ngram_range': (1, 2), 'max_features': 15000},\n    #{'C': 0.01,   'stop_words': None, 'ngram_range': (1, 2), 'max_features': 20000},\n    {'C': 0.01,   'stop_words': None, 'ngram_range': (1, 2), 'max_features': 20000}\n]\n\nbest_f1 = 0\nbest_model = None\nbest_config = None\n\nfor params in param_grid:\n    print(f\"Testing config: {params}\")\n    \n    pipeline = Pipeline([\n        ('tfidf', TfidfVectorizer(\n            max_features=params['max_features'],\n            ngram_range=params['ngram_range'],\n            stop_words=params['stop_words']\n        )),\n        ('svm', LinearSVC(C=params['C']))\n    ])\n    \n    pipeline.fit(X_train, y_train)\n    y_val_pred = pipeline.predict(X_val)\n    \n    report = classification_report(y_val, y_val_pred, output_dict=True, zero_division=0)\n    macro_f1 = report['macro avg']['f1-score']\n    print(f\"Macro F1: {macro_f1:.4f}\")\n    \n    if macro_f1 > best_f1:\n        best_f1 = macro_f1\n        best_model = pipeline\n        best_config = params\n\nprint(\"\\n Best config found:\")\nprint(best_config)\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"y_train_pred = best_model.predict(X_train)\n\n# Print classification report\nprint(\"Training Performance:\")\nprint(classification_report(y_train, y_train_pred, zero_division=0))\n\nfrom sklearn.metrics import classification_report, confusion_matrix\n\n# Predict on validation set using the best pipeline\ny_val_pred = best_model.predict(X_val)\n\n# Print classification report\nprint(\"Validation Performance:\")\nprint(classification_report(y_val, y_val_pred, zero_division=0))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Final evaluation on the test set\ny_test_pred = best_model.predict(X_test)\nprint(\"Test Set Classification Report (final):\")\nprint(classification_report(y_test, y_test_pred, zero_division=0))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\nimport matplotlib.pyplot as plt\n\nclass_names = ['Negative', 'Neutral', 'Positive'] \n\n# Normalized by true class (each row sums to 1)\ncm_norm = confusion_matrix(y_test, y_test_pred, labels=[0, 1, 2], normalize='true')\ndisp_norm = ConfusionMatrixDisplay(confusion_matrix=cm_norm, display_labels=class_names)\n\n\ndisp_norm.plot(values_format='.2f', cmap='Blues')\nplt.title('Confusion Matrix (Test Set)')\nplt.tight_layout()\nplt.savefig('confusion_matrix_normalized.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}